{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:06.288539Z",
     "start_time": "2020-04-29T09:14:05.755092Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import shap\n",
    "import datatable as dt\n",
    "shap.initjs()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T11:29:03.389140Z",
     "start_time": "2020-04-23T11:29:03.387831Z"
    }
   },
   "source": [
    "<H1> Preparing data split: 5 fold cross validation </H1>\n",
    "<br>\n",
    "<h3> The procedure is identical as when splitting data for the purpose of training selected Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:06.647224Z",
     "start_time": "2020-04-29T09:14:06.289574Z"
    }
   },
   "outputs": [],
   "source": [
    "# read original data file\n",
    "df = pd.read_excel(\"./data/source_data/tweet_sentiment_input_file.xlsx\", converters={'dummy_id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:06.650742Z",
     "start_time": "2020-04-29T09:14:06.648307Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop not needed columns\n",
    "df = df.drop([\"row\", \"dummy_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:06.658542Z",
     "start_time": "2020-04-29T09:14:06.651630Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5 fold CV\n",
    "# setup random state\n",
    "np.random.seed(13)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define number of folds\n",
    "fold_number = 5\n",
    "kf = KFold(n_splits=fold_number, random_state=13, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:06.665509Z",
     "start_time": "2020-04-29T09:14:06.659307Z"
    }
   },
   "outputs": [],
   "source": [
    "# create data splits for Deep Learning Language Models trained with Flair framework\n",
    "train_indexes = {}\n",
    "val_indexes = {}\n",
    "test_indexes = {}\n",
    "\n",
    "# train sets for Machine Learning\n",
    "train_ml = {}\n",
    "i = 0\n",
    "\n",
    "# this split (with fold_number=5) results in: 20% test, 10% val, 70% train for Flair framework\n",
    "# and the same 20% test and 80 % train for Machine Learning\n",
    "indexes = list(range(0, len(df)))\n",
    "for train_index, test_index in kf.split(indexes):\n",
    "\n",
    "    test_indexes[i] = test_index\n",
    "    train_ml[i] = train_index\n",
    "    train_index, val_index = train_test_split(train_index, test_size=0.125, random_state=13, shuffle=True)\n",
    "    train_indexes[i] = train_index\n",
    "    val_indexes[i] = val_index\n",
    "    i += 1\n",
    "\n",
    "# test sets for Machine Learning are equal to those for Flair framework\n",
    "test_ml = test_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading data: tweets encoded by various Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linguistic Inquiry and Word Count (LIWC) feature file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:09.948897Z",
     "start_time": "2020-04-29T09:14:06.666256Z"
    }
   },
   "outputs": [],
   "source": [
    "dfliwc = pd.read_excel(\"./data/embeddings/LIWC2015_5k.xlsx\", converters={'dummy_id': str})\n",
    "\n",
    "# rename columns to get unique names\n",
    "dfliwc.rename(columns={'text': 'text_liwc', \"sentiment\": 'liwc_sent'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:09.954675Z",
     "start_time": "2020-04-29T09:14:09.949820Z"
    }
   },
   "outputs": [],
   "source": [
    "# define LIWC features names\n",
    "liwcfeatures = ['WC', 'Analytic', 'Clout', 'Authentic',\n",
    "       'Tone', 'WPS', 'Sixltr', 'Dic', 'function', 'pronoun', 'ppron', 'i',\n",
    "       'we', 'you', 'shehe', 'they', 'ipron', 'article', 'prep', 'auxverb',\n",
    "       'adverb', 'conj', 'negate', 'verb', 'adj', 'compare', 'interrog',\n",
    "       'number', 'quant', 'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad',\n",
    "       'social', 'family', 'friend', 'female', 'male', 'cogproc', 'insight',\n",
    "       'cause', 'discrep', 'tentat', 'certain', 'differ', 'percept', 'see',\n",
    "       'hear', 'feel', 'bio', 'body', 'health', 'sexual', 'ingest', 'drives',\n",
    "       'affiliation', 'achieve', 'power', 'reward', 'risk', 'focuspast',\n",
    "       'focuspresent', 'focusfuture', 'relativ', 'motion', 'space', 'time',\n",
    "       'work', 'leisure', 'home', 'money', 'relig', 'death', 'informal',\n",
    "       'swear', 'netspeak', 'assent', 'nonflu', 'filler', 'AllPunc', 'Period',\n",
    "       'Comma', 'Colon', 'SemiC', 'QMark', 'Exclam', 'Dash', 'Quote',\n",
    "       'Apostro', 'Parenth', 'OtherP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vector representations (embeddings) created by selected Deep Learning Language Models trained previously on here addressed task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:13.024265Z",
     "start_time": "2020-04-29T09:14:09.956006Z"
    }
   },
   "outputs": [],
   "source": [
    "# define which embedding files to read\n",
    "embeddings = [(\"FastText_lstm\", \"fasttext\"), (\"Roberta_lstm\", \"roberta_lstm\"),\n",
    "              (\"Roberta_CLS\", \"roberta_large_ft\")]\n",
    "\n",
    "# instantiate list of data frames with features and a list of feature names for each df\n",
    "dfemblist = []\n",
    "\n",
    "# Initialize a dictionary with all features used later on in Machine Learning\n",
    "allFeatures = {}\n",
    "\n",
    "# read embedding files and define corresponding feature names (lists of names)\n",
    "for emname, embedding in embeddings:\n",
    "    embfeaturedict = {}\n",
    "    for fold in range(fold_number):\n",
    "        # read encoded sentences by the selected language model\n",
    "        dfemb = dt.fread(f\"./data/embeddings/{embedding}_encoded_sentences_{fold}.csv\").to_pandas()\n",
    "        embfeatures = [f\"{emname}{fold}row\"]\n",
    "        \n",
    "        # define number of feature columns (columns - 3)\n",
    "        number_of_feature_columns = len(dfemb.columns) - 3\n",
    "        \n",
    "        # create unique feature (column) names\n",
    "        embfeatures.extend([f\"{emname}{fold}{x}\" for x in range(number_of_feature_columns)])\n",
    "        embfeatures.extend([f\"{emname}{fold}_sentiment_\", f\"{emname}{fold}_dummy_id_\"])\n",
    "        dfemb.columns = embfeatures\n",
    "        \n",
    "        # append features from each language model in tuple ((model_name,fold), [features])\n",
    "        embfeaturedict[fold] = [f\"{emname}{fold}{x}\" for x in range(number_of_feature_columns)]\n",
    "        \n",
    "        # append encoded sentences by the selected language model to a list of data frames\n",
    "        dfemblist.append(dfemb)\n",
    "    \n",
    "    # create entry in dictionary with all features for each trained language model    \n",
    "    allFeatures[emname] = embfeaturedict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vector representations (embeddings) created by selected pre-trained Deep Learning Language Models. No special training was carried out for here addressed task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:13.183634Z",
     "start_time": "2020-04-29T09:14:13.025385Z"
    }
   },
   "outputs": [],
   "source": [
    "# read pooled embeddings and Universal Sentence Encoder (USE) embeddings\n",
    "pooled_embeddings = [[\"Pooled FastText\", \"fasttext\"], [\"Pooled RoBERTa\", \"roberta\"],\n",
    "                     [\"Universal Sentence Encoder\", \"USE\"]]\n",
    "\n",
    "for emname, embedding in pooled_embeddings:\n",
    "    # two options due to naming convention\n",
    "    if emname != \"Universal Sentence Encoder\":\n",
    "        dfemb = dt.fread(f\"./data/embeddings/{embedding}_encoded_sentences_pooled.csv\").to_pandas()\n",
    "    else:\n",
    "        dfemb = dt.fread(f\"./data/embeddings/USE_encoded_sentences.csv\").to_pandas()\n",
    "    \n",
    "    embfeatures = [f\"{emname}row\"]\n",
    "    \n",
    "    # define number of feature columns (columns - 3)\n",
    "    number_of_feature_columns = len(dfemb.columns) - 3\n",
    "    \n",
    "    # create unique feature (column) names\n",
    "    embfeatures.extend([f\"{emname}{x}\" for x in range(number_of_feature_columns)])\n",
    "    embfeatures.extend([f\"{emname}_sentiment_\", f\"{emname}_dummy_id_\"])\n",
    "    dfemb.columns = embfeatures\n",
    "    \n",
    "    # add features from each fold to a local dictionary\n",
    "    embfeaturedict = {}\n",
    "    for fold in range(fold_number): \n",
    "        embfeaturedict[fold] = [f\"{emname}{x}\" for x in range(number_of_feature_columns)]\n",
    "    \n",
    "    # append encoded sentences by the selected language model to a list of data frames\n",
    "    dfemblist.append(dfemb)\n",
    "    \n",
    "    # create entry in dictionary with all features for each language model    \n",
    "    allFeatures[emname] = embfeaturedict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vector representations (embeddings) created by Term Frequency Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:44.153314Z",
     "start_time": "2020-04-29T09:14:36.846959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a per-fold feature dictionary for Term Frequency model\n",
    "foldTFfeatures = {}\n",
    "allWords = []\n",
    "for fold, rows in train_ml.items():\n",
    "    vectorizer = CountVectorizer(min_df=4, binary=True)\n",
    "    tf = vectorizer.fit_transform(dfliwc.iloc[rows][\"text_liwc\"])\n",
    "    dftf = pd.DataFrame(tf.A, columns = vectorizer.get_feature_names())\n",
    "    mi_imps = list(zip(mutual_info_classif(dftf, df.iloc[rows][\"sentiment\"], discrete_features=True), dftf.columns))\n",
    "    mi_imps = sorted(mi_imps, reverse=True)\n",
    "    topFeaturesN = 300\n",
    "    foldTFfeatures[fold] = [f\"TF_{y}\" for x,y in mi_imps[0:topFeaturesN]].copy()\n",
    "    # save all words found by TF models as important features\n",
    "    allWords.extend([y for x,y in mi_imps[0:topFeaturesN]].copy())\n",
    "\n",
    "# add the Term Frequency language model key to dictionary with allFeatures from various language models\n",
    "allFeatures[\"Term Frequency\"] = foldTFfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:44.204428Z",
     "start_time": "2020-04-29T09:14:44.154274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create TF features for all the text instances and create a corresponding data frame\n",
    "allWords = list(set(allWords))\n",
    "vectorizer = CountVectorizer(min_df=4, binary=True, vocabulary=allWords)\n",
    "tf = vectorizer.fit_transform(dfliwc[\"text_liwc\"])\n",
    "dftf = pd.DataFrame(tf.A, columns = vectorizer.get_feature_names())\n",
    "dftf.columns = [f\"TF_{x}\" for x in dftf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:44.222920Z",
     "start_time": "2020-04-29T09:14:44.221130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create per-fold feature dictionary for LIWC model.\n",
    "foldLIWCfeatures = {}\n",
    "for fold, rows in train_ml.items():\n",
    "    foldLIWCfeatures[fold] = liwcfeatures.copy()\n",
    "\n",
    "# add the LIWC language model key to dictionary with allFeatures from various language models\n",
    "allFeatures[\"LIWC\"] = foldLIWCfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTF = {}\n",
    "for fold in range(fold_number):\n",
    "    LTF[fold] = foldLIWCfeatures[fold]\n",
    "    LTF[fold].extend(foldTFfeatures[fold])\n",
    "allFeatures[\"LTF\"] = LTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:48.849220Z",
     "start_time": "2020-04-29T09:14:44.238172Z"
    }
   },
   "outputs": [],
   "source": [
    "# concat all Data Frames: liwc, TF, DL embedding into one df_ml that will be used in Machine Learning\n",
    "dftemp = pd.concat([dfliwc, dftf], axis=1)\n",
    "for dfemb in dfemblist:\n",
    "    dftemp = pd.concat([dftemp, dfemb], axis=1)\n",
    "df_ml = dftemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:48.895859Z",
     "start_time": "2020-04-29T09:14:48.890903Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the target variable in the final df_ml data frame\n",
    "df_ml[\"target_ml\"] = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Machine Learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:48.905430Z",
     "start_time": "2020-04-29T09:14:48.901991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define separate lists of names of trained and not trained language models that can be tested\n",
    "trained_LMs = [\"FastText_lstm\", \"Roberta_lstm\", \"Roberta_CLS\", \"Term Frequency\"]\n",
    "not_trained_LMs = [\"LIWC\", \"Pooled FastText\", \"Pooled RoBERTa\", \"Universal Sentence Encoder\"]\n",
    "explainable_LMs = [\"Term Frequency\", \"LIWC\", \"LTF\"]  # LTF stands for LIWC+Term Frequency features\n",
    "\n",
    "all_language_models = trained_LMs.copy()\n",
    "all_language_models.extend(not_trained_LMs)\n",
    "all_language_models.append(\"LTF\")\n",
    "\n",
    "# a list of all language models\n",
    "# trained_LMs.extend(not_trained_LMs)\n",
    "# all_language_models = trained_LMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:14:48.917448Z",
     "start_time": "2020-04-29T09:14:48.912950Z"
    }
   },
   "outputs": [],
   "source": [
    "# function that trains\n",
    "def ML_classification(classification_model, language_model):\n",
    "    \"\"\"\n",
    "    Function to train classification models on features provided by language models\n",
    "    Example use: classification_model=RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=2,\n",
    "                             min_samples_leaf=1, max_features='auto', n_jobs=-1, random_state=2020)\n",
    "                language_model=\n",
    "    possible options for language model list are: \"Term Frequency\", \"LIWC\", \"Pooled FastText\", \"Pooled RoBERTa\" or \"Universal Sentence Encoder\"\n",
    "    \"\"\"\n",
    "    # list of analyzed language models\n",
    "    model = classification_model\n",
    "    print(type(model).__name__)\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    # for each fold\n",
    "    for fold in range(fold_number):\n",
    "        # chose appropriate features and data\n",
    "        features = set(allFeatures[language_model][fold])\n",
    "        train_index = train_ml[fold]\n",
    "        test_index = test_ml[fold]\n",
    "\n",
    "        train_data = df_ml[features].iloc[train_index]\n",
    "        target_train_data = df_ml[\"target_ml\"].iloc[train_index]\n",
    "        test_data = df_ml[features].iloc[test_index]\n",
    "        target_test_data = df_ml.iloc[test_index][\"target_ml\"]\n",
    "        model.fit(train_data, target_train_data)\n",
    "\n",
    "        preds.append(model.predict(test_data).tolist())\n",
    "        trues.append(target_test_data.tolist())\n",
    "\n",
    "    print(language_model)\n",
    "    mcc = metrics.matthews_corrcoef(y_true=sum(trues, []), y_pred=sum(preds, []))\n",
    "    f1 = metrics.f1_score(y_true=sum(trues, []), y_pred=sum(preds, []), average=\"weighted\")\n",
    "    print(\"MCC: \", round(mcc, 3))\n",
    "    print(\"F1: \", round(f1, 3))\n",
    "    return sum(preds, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T09:17:42.541870Z",
     "start_time": "2020-04-29T09:17:37.534974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "FastText_lstm\n",
      "MCC:  0.445\n",
      "F1:  0.625\n",
      "RandomForestClassifier\n",
      "Roberta_lstm\n",
      "MCC:  0.513\n",
      "F1:  0.671\n",
      "RandomForestClassifier\n",
      "Roberta_CLS\n",
      "MCC:  0.555\n",
      "F1:  0.699\n",
      "RandomForestClassifier\n",
      "Term Frequency\n",
      "MCC:  0.202\n",
      "F1:  0.433\n",
      "RandomForestClassifier\n",
      "LIWC\n",
      "MCC:  0.297\n",
      "F1:  0.526\n",
      "RandomForestClassifier\n",
      "Pooled FastText\n",
      "MCC:  0.286\n",
      "F1:  0.519\n",
      "RandomForestClassifier\n",
      "Pooled RoBERTa\n",
      "MCC:  0.275\n",
      "F1:  0.513\n",
      "RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# instantiate dictionary for data frames with results\n",
    "allPreds = {}\n",
    "\n",
    "# define which classification models to use\n",
    "models = [RandomForestClassifier(n_estimators=1, max_depth=7, min_samples_split=2,\n",
    "                             min_samples_leaf=1, max_features='auto', n_jobs=-1, random_state=2020)]#,\n",
    "#          xgb.XGBClassifier(objective='multi:softprob', n_jobs=24, learning_rate=0.03,\n",
    "#                                  max_depth=10, subsample=0.7, colsample_bytree=0.6,\n",
    "#                                 random_state=2020, n_estimators=1)]\n",
    "\n",
    "# use features from selected language models\n",
    "for language_model in all_language_models:\n",
    "    \n",
    "    # for training of selected classification models\n",
    "    for classification_model in models:\n",
    "        preds = ML_classification(classification_model, language_model)\n",
    "        \n",
    "        # save model predictions\n",
    "        allPreds[f\"{language_model}_{type(classification_model).__name__}\"] = preds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model predictions together with true sentiment labels\n",
    "allPreds[\"sentiment\"] = df[\"sentiment\"]\n",
    "pd.DataFrame(allPreds).to_excel(\"predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Model Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T08:38:46.051448Z",
     "start_time": "2020-04-29T08:38:46.046771Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_for_shap(classification_model, language_model, fold):\n",
    "    \"\"\"\n",
    "    Function to train a single Language Model for SHAP explanations\n",
    "    Example use: classification_model=RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=2,\n",
    "                             min_samples_leaf=1, max_features='auto', n_jobs=-1, random_state=2020),\n",
    "                language_model=\"Term Frequency\",\n",
    "                fold = 2\n",
    "    possible options for language model are: \"Term Frequency\" or \"LIWC\".\n",
    "    possible fold values: 0, 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    # list of analyzed language models\n",
    "    language_model = language_model\n",
    "    fold=fold\n",
    "    model = classification_model\n",
    "    print(type(model).__name__)\n",
    "    results = {}\n",
    "    names = []\n",
    "    \n",
    "    features = set(allFeatures[language_model][fold])\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    train_index = train_ml[fold]\n",
    "    test_index = test_ml[fold]\n",
    "\n",
    "    train_data = df_ml[features].iloc[train_index]\n",
    "    target_train_data = df_ml[\"target_ml\"].iloc[train_index]\n",
    "    test_data = df_ml[features].iloc[test_index]\n",
    "    target_test_data = df_ml.iloc[test_index][\"target_ml\"]\n",
    "    model.fit(train_data, target_train_data)\n",
    "\n",
    "    preds.append(model.predict(test_data).tolist())\n",
    "    trues.append(target_test_data.tolist())\n",
    "    \n",
    "    print(language_model)\n",
    "    mcc = metrics.matthews_corrcoef(y_true=sum(trues, []), y_pred=sum(preds, []))\n",
    "    f1 = metrics.f1_score(y_true=sum(trues, []), y_pred=sum(preds, []), average=\"weighted\")\n",
    "    print(\"MCC: \", round(mcc, 3))\n",
    "    print(\"F1: \", round(f1, 3))\n",
    "    return model, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T08:38:46.061089Z",
     "start_time": "2020-04-29T08:38:46.052231Z"
    }
   },
   "outputs": [],
   "source": [
    "def explain_model(model, train_data, test_data):\n",
    "    \"\"\"\n",
    "    Function that computes and displays SHAP model explanations\n",
    "    \"\"\"\n",
    "    model_name = type(shap_model).__name__\n",
    "    random.seed(13)\n",
    "    if model_name not in [\"RandomForestClassifier\", \"XGBClassifier\"]:\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, train_data[:50], link=\"identity\")\n",
    "        samples_to_explain = 100\n",
    "        shap_values = explainer.shap_values(train_data[:50], nsamples=200, l1_reg=\"num_features(100)\")\n",
    "        shap.summary_plot(shap_values, test_data, max_display=10)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        samples_to_explain = 100\n",
    "        shap_values = explainer.shap_values(train_data)\n",
    "        shap.summary_plot(shap_values, test_data, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T08:38:47.528334Z",
     "start_time": "2020-04-29T08:38:46.061835Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model for SHAP explanations\n",
    "shap_model, train_data, test_data = train_model_for_shap(classification_model=RandomForestClassifier(n_estimators=30, max_depth=7, min_samples_split=2,\n",
    "                             min_samples_leaf=1, max_features='auto', n_jobs=-1, random_state=2020),\n",
    "                            language_model=\"LTF\",\n",
    "                            fold=4)\n",
    "explain_model(model=shap_model, train_data=train_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model for SHAP explanations\n",
    "shap_model, train_data, test_data = train_model_for_shap(classification_model=RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=2,\n",
    "                             min_samples_leaf=1, max_features='auto', n_jobs=-1, random_state=2020),\n",
    "                            language_model=\"Term Frequency\",\n",
    "                            fold=4)\n",
    "explain_model(model=shap_model, train_data=train_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model for SHAP explanations\n",
    "shap_model, train_data, test_data = train_model_for_shap(classification_model=xgb.XGBClassifier(objective='multi:softprob', n_jobs=24, learning_rate=0.03,\n",
    "                                 max_depth=10, subsample=0.7, colsample_bytree=0.6,\n",
    "                                random_state=2020, n_estimators=50),\n",
    "                            language_model=\"LTF\",\n",
    "                            fold=4)\n",
    "explain_model(model=shap_model, train_data=train_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T08:38:47.969182Z",
     "start_time": "2020-04-29T08:38:47.529129Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model for SHAP explanations\n",
    "shap_model, train_data, test_data = train_model_for_shap(classification_model=xgb.XGBClassifier(objective='multi:softprob', n_jobs=24, learning_rate=0.03,\n",
    "                                 max_depth=10, subsample=0.7, colsample_bytree=0.6,\n",
    "                                random_state=2020, n_estimators=40),\n",
    "                                language_model=\"LIWC\",\n",
    "                                fold=0)\n",
    "explain_model(model=shap_model, train_data=train_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T08:38:48.584766Z",
     "start_time": "2020-04-29T08:38:47.970039Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model for SHAP explanations\n",
    "shap_model, train_data, test_data = train_model_for_shap(classification_model=xgb.XGBClassifier(objective='multi:softprob', n_jobs=24, learning_rate=0.03,\n",
    "                                 max_depth=10, subsample=0.7, colsample_bytree=0.6,\n",
    "                                random_state=2020, n_estimators=20),\n",
    "                                language_model=\"Universal Sentence Encoder\",\n",
    "                                fold=0)\n",
    "explain_model(model=shap_model, train_data=train_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-29T08:38:16.804Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model for SHAP explanations\n",
    "shap_model, train_data, test_data = train_model_for_shap(classification_model=MultinomialNB(),\n",
    "                                                         language_model=\"LIWC\",\n",
    "                                                         fold=0)\n",
    "explain_model(model=shap_model, train_data=train_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model for SHAP explanations\n",
    "shap_model, train_data, test_data = train_model_for_shap(classification_model=MultinomialNB(),\n",
    "                                    language_model=\"Term Frequency\",\n",
    "                                    fold=0)\n",
    "explain_model(model=shap_model, train_data=train_data, test_data=test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
